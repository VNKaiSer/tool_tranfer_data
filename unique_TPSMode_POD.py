import mysql.connector
from mysql.connector import Error
from dotenv import load_dotenv
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import time

# Load c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

BATCH_SIZE = 3_000_000
TABLE_SOURCE = "NK2025"
TABLE_TARGET = "VNPort_TPSMode"
MAX_WORKERS = 4  # S·ªë l∆∞·ª£ng threads ch·∫°y song song (ƒëi·ªÅu ch·ªânh t√πy theo server)

# Lock ƒë·ªÉ ƒë·∫£m b·∫£o print kh√¥ng b·ªã xung ƒë·ªôt
print_lock = Lock()


def get_db_config_source():
    """L·∫•y th√¥ng tin k·∫øt n·ªëi database ngu·ªìn t·ª´ bi·∫øn m√¥i tr∆∞·ªùng"""
    return {
        "host": os.getenv("DB_HOST_SOURCE"),
        "user": os.getenv("DB_USER_SOURCE"),
        "password": os.getenv("DB_PASSWORD_SOURCE"),
        "database": os.getenv("DB_NAME_SOURCE"),
    }


def get_db_config_target():
    """L·∫•y th√¥ng tin k·∫øt n·ªëi database ƒë√≠ch t·ª´ bi·∫øn m√¥i tr∆∞·ªùng"""
    return {
        "host": os.getenv("DB_HOST_TARGET"),
        "user": os.getenv("DB_USER_TARGET"),
        "password": os.getenv("DB_PASSWORD_TARGET"),
        "database": os.getenv("DB_NAME_TARGET"),
    }


def process_batch(batch_info):
    """
    X·ª≠ l√Ω m·ªôt batch d·ªØ li·ªáu
    - SELECT t·ª´ database ngu·ªìn
    - INSERT v√†o database ƒë√≠ch
    M·ªói thread c√≥ connection ri√™ng ƒë·ªÉ tr√°nh conflict
    """
    batch_num, batch_start, batch_end = batch_info
    conn_source = None
    conn_target = None

    try:
        # T·∫°o connection ƒë·∫øn database ngu·ªìn
        config_source = get_db_config_source()
        conn_source = mysql.connector.connect(**config_source)
        cursor_source = conn_source.cursor(dictionary=True)

        # T·∫°o connection ƒë·∫øn database ƒë√≠ch
        config_target = get_db_config_target()
        conn_target = mysql.connector.connect(**config_target)
        cursor_target = conn_target.cursor()

        with print_lock:
            print(f"üöÄ Thread {batch_num}: ƒêang x·ª≠ l√Ω id {batch_start} -> {batch_end}")

        start_time = time.time()

        # B∆∞·ªõc 1: SELECT DISTINCT t·ª´ database ngu·ªìn
        select_query = f"""
            SELECT DISTINCT TPSMode, POD
            FROM {TABLE_SOURCE}
            WHERE Id BETWEEN {batch_start} AND {batch_end}
            AND TPSMode IS NOT NULL 
            AND POD IS NOT NULL
        """
        cursor_source.execute(select_query)
        data = cursor_source.fetchall()

        rows_affected = 0
        values = []

        # B∆∞·ªõc 2: INSERT v√†o database ƒë√≠ch
        if data:
            insert_query = f"""
                INSERT IGNORE INTO {TABLE_TARGET} (TPSMode, Port)
                VALUES (%s, %s)
            """
            # Chuy·ªÉn ƒë·ªïi dict th√†nh tuple, l·ªçc NULL values
            w
            values = [
                (row["TPSMode"], row["POD"])
                for row in data
                if row["TPSMode"] and row["POD"]
            ]

            if values:
                with print_lock:
                    print(
                        f"   ‚Ü≥ Batch #{batch_num}: Chu·∫©n b·ªã insert {len(values)} unique records..."
                    )
                    # In ra 2 record ƒë·∫ßu ƒë·ªÉ debug
                    if len(values) >= 2:
                        print(f"   ‚Ü≥ Sample data: {values[0]}, {values[1]}")

                cursor_target.executemany(insert_query, values)
                conn_target.commit()
                rows_affected = cursor_target.rowcount

                with print_lock:
                    print(
                        f"   ‚Ü≥ Batch #{batch_num}: INSERT tr·∫£ v·ªÅ rowcount = {rows_affected}"
                    )
            else:
                with print_lock:
                    print(
                        f"   ‚ö†Ô∏è Batch #{batch_num}: Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l·ªçc NULL"
                    )
        else:
            with print_lock:
                print(f"   ‚ö†Ô∏è Batch #{batch_num}: SELECT kh√¥ng tr·∫£ v·ªÅ d·ªØ li·ªáu n√†o")

        elapsed_time = time.time() - start_time

        with print_lock:
            print(
                f"‚úÖ Batch #{batch_num} ho√†n t·∫•t: "
                f"ƒë·ªçc {len(data)} rows, insert {len(values)} values, "
                f"affected {rows_affected} rows "
                f"({elapsed_time:.2f}s)"
            )

        return {
            "batch_num": batch_num,
            "rows_read": len(data),
            "rows_affected": rows_affected,
            "success": True,
            "elapsed_time": elapsed_time,
        }

    except Error as e:
        with print_lock:
            print(f"‚ùå Batch #{batch_num} l·ªói: {e}")
        return {
            "batch_num": batch_num,
            "rows_read": 0,
            "rows_affected": 0,
            "success": False,
            "error": str(e),
        }

    finally:
        # ƒê√≥ng connection ngu·ªìn
        if conn_source and conn_source.is_connected():
            cursor_source.close()
            conn_source.close()

        # ƒê√≥ng connection ƒë√≠ch
        if conn_target and conn_target.is_connected():
            cursor_target.close()
            conn_target.close()


def main():
    try:
        # K·∫øt n·ªëi ƒë·∫øn database ngu·ªìn ƒë·ªÉ l·∫•y max_id
        config_source = get_db_config_source()
        conn_source = mysql.connector.connect(**config_source)
        cursor_source = conn_source.cursor(dictionary=True)

        print("üîç ƒêang ki·ªÉm tra d·ªØ li·ªáu t·ª´ database ngu·ªìn...")

        # L·∫•y max id t·ª´ b·∫£ng ngu·ªìn (l∆∞u √Ω: c·ªôt l√† Id v·ªõi ch·ªØ I vi·∫øt hoa)
        cursor_source.execute(f"SELECT MAX(Id) AS max_id FROM {TABLE_SOURCE}")
        max_id = cursor_source.fetchone()["max_id"]

        cursor_source.close()
        conn_source.close()

        if not max_id:
            print("‚ö†Ô∏è B·∫£ng ngu·ªìn tr·ªëng, kh√¥ng c√≥ d·ªØ li·ªáu.")
            return

        print(f"üìä T·ªïng s·ªë records: {max_id:,}")
        print(f"üìÅ Database ngu·ªìn: {config_source['database']} ‚Üí Table: {TABLE_SOURCE}")
        print(
            f"üìÅ Database ƒë√≠ch: {os.getenv('DB_NAME_TARGET')} ‚Üí Table: {TABLE_TARGET}"
        )
        print(f"‚öôÔ∏è  Batch size: {BATCH_SIZE:,}")
        print(f"üî¢ S·ªë threads: {MAX_WORKERS}")

        # T·∫°o danh s√°ch c√°c batch c·∫ßn x·ª≠ l√Ω
        batches = []
        batch_start = 1
        batch_num = 1

        while batch_start <= max_id:
            batch_end = min(batch_start + BATCH_SIZE - 1, max_id)
            batches.append((batch_num, batch_start, batch_end))
            batch_start = batch_end + 1
            batch_num += 1

        total_batches = len(batches)
        print(f"üì¶ T·ªïng s·ªë batches: {total_batches}")

        # Validation: Ki·ªÉm tra c√°c batch kh√¥ng overlap
        print("\nüîç Ki·ªÉm tra batch ranges ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng tr√πng ID:")
        for i, (num, start, end) in enumerate(batches):
            print(f"   Batch #{num}: Id {start:,} ‚Üí {end:,} ({end - start + 1:,} ids)")

            # Validate: batch sau ph·∫£i b·∫Øt ƒë·∫ßu sau batch tr∆∞·ªõc
            if i > 0:
                prev_end = batches[i - 1][2]
                if start != prev_end + 1:
                    print(
                        f"   ‚ö†Ô∏è  WARNING: Gap detected! Previous end: {prev_end}, Current start: {start}"
                    )
                if start <= prev_end:
                    print(
                        f"   ‚ùå ERROR: Overlap detected! Previous end: {prev_end}, Current start: {start}"
                    )
                    raise ValueError(
                        "Batch ranges overlap! D·ª´ng ƒë·ªÉ tr√°nh x·ª≠ l√Ω tr√πng l·∫∑p."
                    )

        print("‚úÖ T·∫•t c·∫£ batch ranges h·ª£p l·ªá, kh√¥ng c√≥ overlap")
        print("=" * 60)

        # X·ª≠ l√Ω song song v·ªõi ThreadPoolExecutor
        start_time = time.time()
        total_rows_read = 0
        total_rows_inserted = 0
        success_count = 0
        failed_count = 0

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # Submit t·∫•t c·∫£ c√°c batch jobs
            future_to_batch = {
                executor.submit(process_batch, batch): batch for batch in batches
            }

            # X·ª≠ l√Ω k·∫øt qu·∫£ khi ho√†n th√†nh
            for future in as_completed(future_to_batch):
                result = future.result()
                if result["success"]:
                    success_count += 1
                    total_rows_read += result["rows_read"]
                    total_rows_inserted += result["rows_affected"]
                else:
                    failed_count += 1

        total_time = time.time() - start_time

        # T·ªïng k·∫øt
        print("=" * 60)
        print("üéâ HO√ÄN T·∫§T!")
        print(f"‚úÖ Th√†nh c√¥ng: {success_count}/{total_batches} batches")
        if failed_count > 0:
            print(f"‚ùå Th·∫•t b·∫°i: {failed_count}/{total_batches} batches")
        print(f"üìñ T·ªïng s·ªë h√†ng ƒë·ªçc t·ª´ ngu·ªìn: {total_rows_read:,}")
        print(f"üìä T·ªïng s·ªë h√†ng th√™m m·ªõi v√†o ƒë√≠ch: {total_rows_inserted:,}")
        print(f"‚è±Ô∏è  T·ªïng th·ªùi gian: {total_time:.2f}s")
        if total_rows_inserted > 0:
            print(f"üöÄ T·ªëc ƒë·ªô trung b√¨nh: {total_rows_inserted/total_time:.0f} rows/s")

    except Error as e:
        print(f"‚ùå L·ªói MySQL: {e}")
    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")


if __name__ == "__main__":
    main()
